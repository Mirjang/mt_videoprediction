<html lang="en">

 <!--"most of the syntax is "borrowed" from https://saic-mdal.github.io/deep-landscape/ i have no idea what it does, but apparently you cant embed videos using markup and i dont wana lean html:)-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="author" content="P. Radner">
    
  <!-- <style>
  video {
    height: 100%;
    width: 100%; 
    resize:both;
  }


  /* general styling */
  :root {
    font-size: calc(1vw + 1vh + .5vmin);
  }
  </style> -->

  <script>
    MathJax = {
      tex: {
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>

  <title>MT: Style Based Video Prediction</title>


  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link href="vendor/simple-line-icons/css/simple-line-icons.css" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic" rel="stylesheet"
    type="text/css">

  <!-- Custom styles for this template -->
  <link href="css/landing-page.min.css" rel="stylesheet">

</head>

<body>
    <!-- Masthead -->
    <!-- <header class="masthead text-white text-center">
        <div class="container">
          <div class="overlay"></div>
          <div class="row">
            <!-- <div class="offset-md-1 col-md-10">
              <video class="video video-header" loop="loop" autoplay muted>
                <source src="vids/test.webm" type="video/webm" />
                Your browser doesn't support .webm video
              </video>
            </div> -->
            <!-- <div class="col-xl-9 mx-auto">
              <br /><br />
            </div>
          </div>
        </div>
      </header> -->
    <h1 class="mb-5"><span class="title">Masterâ€™s Thesis: [TBD] - Supplementary Material</span></h1>

    <!-- cvt mp4s to webms: (needed a place to store that)-->
    <!-- ffmpeg -i input.mp4 -c:v libvpx-vp9 -crf 30 -b:v 0 -b:a 128k -c:a libopus output.webm -->
    <!-- for i in `ls`; do ffmpeg -i $i -c:v libvpx-vp9 -crf 30 -b:v 0 -b:a 128k -c:a libopus $i.webm ; done -->

    <!-- for i in `ls`; do ffprobe -v error -select_streams v:0 -show_entries stream=nb_frames -of default=nokey=1:noprint_wrappers=1 $i ; done -->

    <section class="showcase">
        <div class="container">
          <div class="row myrow">
            <div class="offset-md-1 col-md-10">
              <h2>Abstract</h2>
              <p class="lead mb-0" align="justify">
                "In this work a novel architecture is developed to perform video prediction. In particular the task of "bringing landscape images to live" is investigated.
                 This is an especially challenging video prediction task, as only a single input image is given and the model has to predict what might happen next in the
                  scene, for example clouds moving or flowing rivers and waterfalls. The changes per frame in these types of videos are usually very small detailed.
                   As no flow or segmentation is given the model also has to learn, which image elements to animate. 
                <!-- <br/><br/> -->
                The proposed architecture combines recurrent, feature pyramid architectures from previous works such as DVD-GAN with styled convolutions introduced by
                 StyleGAN to predict the final video. 
                <!-- <br/><br/> -->
                A new dataset for the task of "bringing landscape images to live", which focuses on fine details rather than global changes. The proposed model is evaluated
                gainst state-of-the-art baselines and is shown to also work on standard video prediction benchmarks, while requiring smaller compute resources for training.      
                "
            </p>

            <img src="imgs/style_arch.png" style="width:512px;height:512px;"/>
            <p>Video prediction architecture based on <a href = https://arxiv.org/abs/1912.04958>StyleGAN2</a> and <a href="https://arxiv.org/abs/1907.06571">DVD-GAN</a>. 
              The green arrow indicates the predicted style vector.
               The dashed red line logically separates the generator into an encoder and decoder part.</p>
            </div>
          </div>
        </div>


        <h2>Showcase: Custom Dastaset</h2>
        <div class ="row">
          <video class="video video-grid img-fluid" loop="loop" autoplay="" muted="">
          <source src="vids/style128_sample/fake_block7.mp4.webm" type="video/webm">
          </video>
          <video class="video video-grid img-fluid" loop="loop" autoplay="" muted="">
          <source src="vids/style128_sample/fake_block25.mp4.webm" type="video/webm">
          </video>
          <video class="video video-grid img-fluid" loop="loop" autoplay="" muted="">
          <source src="vids/style128_sample/fake_block40.mp4.webm" type="video/webm">
          </video>
        </div>
        <div class ="row">
          <video class="video video-grid img-fluid" loop="loop" autoplay="" muted="">
          <source src="vids/style128_sample/fake_block77.mp4.webm" type="video/webm">
          </video>
          <video class="video video-grid img-fluid" loop="loop" autoplay="" muted="">
          <source src="vids/style128_sample/fake_block128.mp4.webm" type="video/webm">
          </video>
          <video class="video video-grid img-fluid" loop="loop" autoplay="" muted="">
          <source src="vids/style128_sample/fake_block117.mp4.webm" type="video/webm">
          </video>
        </div>
        <div class ="row">
          <video class="video video-grid img-fluid" loop="loop" autoplay="" muted="">
          <source src="vids/style128_sample/fake_block164.mp4.webm" type="video/webm">
          </video>
          <video class="video video-grid img-fluid" loop="loop" autoplay="" muted="">
          <source src="vids/style128_sample/fake_block177.mp4.webm" type="video/webm">
          </video>
          <video class="video video-grid img-fluid" loop="loop" autoplay="" muted="">
          <source src="vids/style128_sample/fake_block185.mp4.webm" type="video/webm">
          </video>
        </div>


        <!-- <div class="container"> -->
        <h2>Comparison</h2>
        <div class="row">
          <video class="video video-grid img-fluid" loop="loop" autoplay="" muted="">
              <source src="vids/bair_cmp/style/out.webm" type="video/webm">
          </video>
        </div>
        <div class="row">
          <video class="video video-grid img-fluid" loop="loop" autoplay="" muted="">
            <source src="vids/bair_cmp/dvd/out.webm" type="video/webm">
          </video>
        </div>
        <p>Comparison between our method (top) and a down-scaled version of DVD-GAN (bottom) on the bair robot pushing dataset.</p>
        <!-- </div> -->

        <h2>Showcase: GauGAN videos</h2>
        <div class="row">
          <video class="video video-grid img-fluid" loop="loop" autoplay="" muted="">
              <source src="vids/gau_block.webm" type="video/webm">
          </video>
        </div>
        <p>
        Video prediction on images created with <a href="https://www.nvidia.com/en-us/research/ai-playground/"><b> NVidia GauGAN </b></a>.
        The video prediction model was trained on our custom dataset. 
        </p>
  <!-- 
          <div class="offset-md-1 col-md-8 row iframe-container col-md-10">
            <iframe src="https://www.youtube.com/embed/2CoQRf5qXWY" frameborder="0"
              allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div> -->

      </section>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
</body>

</html>